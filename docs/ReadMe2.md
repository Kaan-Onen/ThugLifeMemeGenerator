ğŸ˜ The Thug Life Meme Generator 
Welcome to the ultimate Computer Vision project! Weâ€™re using cutting-edge tech to automatically drop "Thug Life" assets onto faces with pinpoint precision. Whether it's a static boss move or a video that triggers on a blink, this Python-powered tool has you covered.âœ¨  


ğŸš€ Key Features  
ğŸ–¼ï¸ Static Image Overlay: Automatically scales and rotates assets based on the distance and angle between the eyes. No manual tweaking needed!  
ğŸ¥ Video Magic: Real-time processing that detects when you blink. Close your eyes, and boomâ€”the meme appears.  
ğŸ“ Smart Anchoring: Assets are locked to specific facial landmarks, ensuring they don't just float around.  
ğŸ”„ Dynamic Rotation: Whether your head is tilted or you're leaning back, the assets adjust their angle using eye-coordinate math for a perfect fit.  


ğŸ› ï¸ The Tech Stack  
This project is built with Python and a trio of powerhouse libraries:  

MediaPipe: The "eyes" of the project, used for high-fidelity face landmarking.  
ğŸ§OpenCV: The engine for image and video manipulation.   
ğŸ¬NumPy: The "brain" handling all the coordinate geometry and matrix transformations.   

ğŸ”¢ğŸ“‚ Project StructurePlaintext  
â”œâ”€â”€ .venv/          # Isolated virtual environment  
â”œâ”€â”€ assets/         # Glasses, hats, blunts, and your raw media ğŸ•¶ï¸  
â”œâ”€â”€ docs/           # Documentation and guides  
â”œâ”€â”€ models/         # The face_landmarker.task file ğŸ¤–  
â”œâ”€â”€ src/            # Python scripts (image.py, video.py, etc.)  
â””â”€â”€ requirements.txt # The "shopping list" of dependencies  


ğŸ§  How the Magic HappensThe project leverages the MediaPipe FaceLandmarker to map the face in 3D space. The secret sauce lives in vision_utils.py, which handles:  
Scaling: Resizes the asset dynamically based on how close you are to the camera.  
Rotation: Uses $cv2.getRotationMatrix2D$ to calculate the exact tilt between your eyes.  
Alpha Blending: Uses PNG transparency (the alpha channel) so the shades look like they're actually on your face, not just pasted on top.ğŸ¨  


ğŸ¬ Getting Started  
1. Install Dependencies Get your environment ready with one command:pip install -r requirements.txt ğŸ’»  
2. Models and Assets *   
Drop the face_landmarker.task model into the models/ folder.  
Throw your swagger (glasses, hats, etc.) and your test videos into the assets/ folder. ğŸ“‚  
3. Run the Scripts *   
For Photos: python image.py ğŸ“¸  
For Videos: python video.py ğŸ“¹  
  
